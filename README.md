# Bumblebee Trusts Wikipedia (BTW)

A simple Siri-style assistant for Linux/Hyprland made using speech-to-text from Groq Whisper,and the responses come from the Mistral API.

## Overview
- Listening is handled by `vad_record.py` (webrtcvad) and auto-stops on silence.
- STT uses Groq Whisper via a small Bash script.
- LLM replies are generated by Mistral Chat Completions.
- TTS uses Groq TTS; audio is played with `aplay`.
- UI is a minimal YAD popup rendered from simple HTML (no heavy frameworks).


## Requirements
- Linux with a working microphone (Hyprland optional).
- System packages: `yad`, `jq`, `curl`, `alsa-utils` (`aplay`).
- Python 3.9+ with venv.
- Runtime library: `portaudio` (Arch package providing `libportaudio.so` required by `sounddevice`).

## Python Dependencies
Defined in `requirements.txt`:
- `webrtcvad==2.0.10`
- `sounddevice>=0.4.6`
- `numpy>=1.21`
- `setuptools>=60` (provides `pkg_resources` used by some deps)

## Setup
```zsh
# 1) Create and activate a virtual environment
python3 -m venv .venv
source .venv/bin/activate

# 2) Install Python dependencies
pip install --upgrade pip setuptools wheel
pip install -r requirements.txt

# 3) Install PortAudio runtime for sounddevice (Arch Linux)
sudo pacman -Syu --noconfirm
sudo pacman -S --noconfirm portaudio

# 4) Ensure YAD and ALSA utilities are installed (Arch Linux)
sudo pacman -S --noconfirm yad jq curl alsa-utils

# Alternatively, using paru (AUR helper)
# paru -S yad jq curl alsa-utils portaudio
```

## Configuration
Create or edit `scripts/env.sh` with your API keys (do not commit secrets):
```bash
export GROQ_API_KEY="gsk_..."      # Groq (STT & TTS)
export MISTRAL_API_KEY="sk_..."    # Mistral (LLM)
```
`assistant.sh` sources this file at startup.

## Usage
```zsh
# Make scripts executable
chmod +x scripts/*.sh

# Start the assistant (from repo root)
scripts/assistant.sh
```

## Project Structure
```
btw/
├── README.md
├── assets/
├── scripts/
│   ├── assistant.sh
│   ├── env.sh
│   ├── stt.sh
│   ├── tts.sh
│   └── vad_record.py
├── tmp/
│   ├── query.wav
│   └── tts_output.wav
└── ui/
	├── ass2.css
	├── assistant.css
	├── listening.html
	├── processing.html
	└── reply.html
```

